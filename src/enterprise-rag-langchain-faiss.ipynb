{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPxDVzmhjmVRtO1nAErmaKZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JV9hbua64NU","executionInfo":{"status":"ok","timestamp":1754814378553,"user_tz":-330,"elapsed":20339,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"a64a6831-90f3-47b9-b7c8-018ac201d1d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4qKXt8e7IWe","executionInfo":{"status":"ok","timestamp":1754815553533,"user_tz":-330,"elapsed":127,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"0ab359f4-4aba-41f8-e5e7-76c5b2481746"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Aug 10 08:45:53 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# Install core libraries for the RAG prototype.\n","# -qU = quiet output + upgrade to latest compatible versions\n","# langchain            : framework for chaining LLM + retriever steps\n","# langchain-community  : community loaders/vector stores (e.g., DirectoryLoader, FAISS)\n","# langchain-openai     : OpenAI wrappers (ChatOpenAI, OpenAIEmbeddings)\n","# tiktoken             : OpenAI tokenizer for token counting/chunking\n","!pip install -qU langchain langchain-community langchain-openai tiktoken"],"metadata":{"id":"zT8R13yxXk5c","executionInfo":{"status":"ok","timestamp":1754815560329,"user_tz":-330,"elapsed":4590,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Install FAISS with GPU\n","# Use only if your Colab runtime has an NVIDIA GPU (check using command \"!nvidia-smi\").\n","# -qU = quiet + upgrade. If this fails (CUDA mismatch/no GPU), use \"pip install -qU faiss-cpu\"\n","!pip install -qU faiss-gpu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFee5aRAYHPz","executionInfo":{"status":"ok","timestamp":1754815567703,"user_tz":-330,"elapsed":4710,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"2df7aa6d-8f11-4ce1-aec4-2042eca82139"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# Using CPU, as GPU command doesn't work.\n","!pip install -qU faiss-cpu"],"metadata":{"id":"0Z42wWpFZp0W","executionInfo":{"status":"ok","timestamp":1754815577019,"user_tz":-330,"elapsed":8027,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Quick environment sanity-check: print Python version\n","import sys, subprocess, importlib, os\n","print(\"Python:\", sys.version.split()[0])\n","\n","# Helper: print the installed version of a package (skip gracefully if unavailable)\n","def ver(pkg):\n","    try:\n","        from importlib.metadata import version  # standard way to fetch package version\n","        print(pkg, version(pkg))\n","    except Exception as e:\n","        print(pkg, \"— version check skipped:\", e)\n","\n","# Report versions of core libraries used in this RAG prototype\n","ver(\"langchain\"); ver(\"langchain-community\"); ver(\"langchain-openai\"); ver(\"tiktoken\")\n","\n","# Verify FAISS availability and show its version; catch import issues cleanly\n","try:\n","    import faiss\n","    print(\"faiss:\", faiss.__version__ if hasattr(faiss, \"__version__\") else \"ok\")\n","except Exception as e:\n","    print(\"faiss import error:\", e)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YHUxsZJqmDW","executionInfo":{"status":"ok","timestamp":1754815579349,"user_tz":-330,"elapsed":40,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"535cb812-d6a6-458f-cd56-7aadacd025da"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Python: 3.11.13\n","langchain 0.3.27\n","langchain-community 0.3.27\n","langchain-openai 0.3.29\n","tiktoken 0.11.0\n","faiss: 1.11.0\n"]}]},{"cell_type":"code","source":["# Verify FAISS is installed and importable.\n","# This confirms a CPU-only install.\n","import faiss\n","print(\"FAISS OK (CPU)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8J4MbGfoaAHY","executionInfo":{"status":"ok","timestamp":1754815583645,"user_tz":-330,"elapsed":15,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"d341f533-d17c-44ca-b49f-a70630e811a6"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["FAISS OK (CPU)\n"]}]},{"cell_type":"code","source":["# Securely prompt for your OpenAI API key\n","import os\n","from getpass import getpass\n","\n","# Save the key to an environment variable for this session\n","os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n","\n","# Confirm setup (does not print the key)\n","print(\"OpenAI key set\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wo_7iTZoc_za","executionInfo":{"status":"ok","timestamp":1754815596973,"user_tz":-330,"elapsed":11365,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"03450f23-4d91-4e84-fa34-0d00156dfa43"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your OpenAI API key: ··········\n","OpenAI key set\n"]}]},{"cell_type":"code","source":["# Verify files exist in Drive\n","# Lists all .txt files in the target folder so you can confirm names/count.\n","from pathlib import Path\n","\n","DATA_DIR = Path(\"/content/drive/MyDrive/enterprise-rag-langchain-faiss/data\")\n","files = sorted(DATA_DIR.glob(\"*.txt\"))\n","print(f\"Found {len(files)} .txt files:\")\n","for p in files:\n","    print(\"•\", p.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tp6MW8-fqznH","executionInfo":{"status":"ok","timestamp":1754815598940,"user_tz":-330,"elapsed":9,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"12a383b9-3a28-4445-e3c6-eff23fe62ce1"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5 .txt files:\n","• basel3_overview.txt.txt\n","• fatf_recs_overview.txt.txt\n","• iso20022_about.txt.txt\n","• open_banking_what_is.txt.txt\n","• psd2_intro.txt.txt\n"]}]},{"cell_type":"code","source":["# Load the .txt files as LangChain Documents\n","# DirectoryLoader + TextLoader read files and attach basic metadata.\n","from langchain_community.document_loaders import DirectoryLoader, TextLoader\n","\n","loader = DirectoryLoader(\n","    str(DATA_DIR),\n","    glob=\"*.txt\",\n","    loader_cls=TextLoader,\n","    loader_kwargs={\"encoding\": \"utf-8\"},\n","    show_progress=True,\n",")\n","docs = loader.load()\n","print(f\"Loaded {len(docs)} documents\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29eOvrL7q5pV","executionInfo":{"status":"ok","timestamp":1754815600666,"user_tz":-330,"elapsed":21,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"e4048c1b-f7ce-4228-d75a-759a8f303983"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:00<00:00, 506.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Loaded 5 documents\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Preview of loaded content\n","# Prints each filename, character count, and a snippet for sanity-checks.\n","from pathlib import Path\n","\n","for d in docs:\n","    src = Path(d.metadata.get(\"source\", \"?\")).name\n","    snippet = d.page_content[:400].replace(\"\\n\", \" \")\n","    print(f\"\\n— {src} ({len(d.page_content)} chars)\")\n","    print(snippet + (\"...\" if len(d.page_content) > 400 else \"\"))"],"metadata":{"id":"GdNwdLWLrA02","executionInfo":{"status":"ok","timestamp":1754815603862,"user_tz":-330,"elapsed":22,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"798674b0-9119-449d-fa57-51c223456027","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","— basel3_overview.txt.txt (4888 chars)\n","The Basel III reforms have now been integrated into the consolidated Basel Framework, which comprises all of the current and forthcoming standards of the Basel Committee on Banking Supervision. For background, set out below are the main publications that describe the changes to the Basel Framework that were agreed as part of Basel III.  Basel III is an internationally agreed set of measures develo...\n","\n","— psd2_intro.txt.txt (7129 chars)\n","The revised Payment Services Directive (PSD2) updates and enhances the EU rules put in place by the initial PSD adopted in 2007. The PSD2 entered into force on 12 January 2016 and EU Member States were given until 13 January 2018 to transpose it into national law.  The main objectives of the PSD2 are (i) to contribute to a more integrated and efficient European payments market; (ii) to further lev...\n","\n","— fatf_recs_overview.txt.txt (55389 chars)\n"," INTERNATIONAL STANDARDS ON COMBATING MONEY LAUNDERING AND THE FINANCING OF TERRORISM & PROLIFERATION   INTRODUCTION  The Financial Action Task Force (FATF) is an inter-governmental body established in 1989 by the Ministers of its Member jurisdictions. The mandate of the FATF is to set standards and to promote effective implementation of legal, regulatory and operational measures for combating mon...\n","\n","— open_banking_what_is.txt.txt (2745 chars)\n","WHAT IS OPEN BANKING? Open banking is a simple, secure way to help you move, manage and make more of your money. Savings or investments. Budgeting or donating. Affordable loans and cost-effective payments. Open banking powers new ways for consumers and businesses to access a wide range of financial services – all built on secure systems from regulated providers. Many organisations, including HMRC ...\n","\n","— iso20022_about.txt.txt (1959 chars)\n","About ISO 20022 ISO 20022 is an open global standard for financial information. It provides consistent, rich and structured data that can be used for every kind of financial business transaction. Don’t get left behind, the coexistence period for payment instructions is scheduled to end on 22 November 2025.  ISO 20022 for Financial Institutions: Focus on payments instructions ISO 20022 is transform...\n"]}]},{"cell_type":"code","source":["# Choose chunk size and overlap (safe defaults for GPT context windows)\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","CHUNK_SIZE = 1000\n","CHUNK_OVERLAP = 200\n","\n","splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=CHUNK_SIZE,\n","    chunk_overlap=CHUNK_OVERLAP\n",")\n","print(\"Chunking params set.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PSdcj3jGyao","executionInfo":{"status":"ok","timestamp":1754815606838,"user_tz":-330,"elapsed":10,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"a7bd95b1-c636-414a-fa14-8308c1406319"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunking params set.\n"]}]},{"cell_type":"code","source":["# Split the loaded documents (variable `docs`)\n","chunks = splitter.split_documents(docs)\n","print(f\"Created {len(chunks)} chunks from {len(docs)} documents.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ibuy2Ry5HA1Q","executionInfo":{"status":"ok","timestamp":1754815608811,"user_tz":-330,"elapsed":13,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"f027fcb0-2b09-4dd0-9590-6d603fc33e40"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Created 110 chunks from 5 documents.\n"]}]},{"cell_type":"code","source":["# Add a running chunk_id so answers can reference sources cleanly\n","for i, c in enumerate(chunks):\n","    c.metadata[\"chunk_id\"] = i\n","\n","# Quick peek\n","for c in chunks[:3]:\n","    src = c.metadata.get(\"source\", \"?\")\n","    print(f\"[chunk_id={c.metadata['chunk_id']}] {src} :: {len(c.page_content)} chars\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uH3tXlTCHHsB","executionInfo":{"status":"ok","timestamp":1754815610220,"user_tz":-330,"elapsed":14,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"3e703e44-aa5c-473d-be01-cc01926e2d9a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["[chunk_id=0] /content/drive/MyDrive/enterprise-rag-langchain-faiss/data/basel3_overview.txt.txt :: 849 chars\n","[chunk_id=1] /content/drive/MyDrive/enterprise-rag-langchain-faiss/data/basel3_overview.txt.txt :: 804 chars\n","[chunk_id=2] /content/drive/MyDrive/enterprise-rag-langchain-faiss/data/basel3_overview.txt.txt :: 933 chars\n"]}]},{"cell_type":"code","source":["# Check token sizes so we know they fit comfortably in prompts\n","import tiktoken\n","enc = tiktoken.get_encoding(\"cl100k_base\")\n","\n","lengths = [len(enc.encode(c.page_content)) for c in chunks]\n","print(\n","    f\"Chunks: {len(chunks)} | tokens per chunk -> \"\n","    f\"min={min(lengths)}, p50={sorted(lengths)[len(lengths)//2]}, max={max(lengths)}\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrZeDE9OHNya","executionInfo":{"status":"ok","timestamp":1754815612938,"user_tz":-330,"elapsed":21,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"6d00fc84-95d1-4e97-f890-bea7db78b25f"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunks: 110 | tokens per chunk -> min=9, p50=131, max=208\n"]}]},{"cell_type":"code","source":["# SentenceTransformers is used to get local embeddings\n","!pip install -qU langchain-huggingface sentence-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bx3WQWTkNEyt","executionInfo":{"status":"ok","timestamp":1754816352330,"user_tz":-330,"elapsed":4652,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"39a930f1-1b8a-4cdd-9946-f01d14eefbd1"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/483.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m481.3/483.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Initialise Hugging Face embeddings (latest supported import)\n","from langchain_huggingface import HuggingFaceEmbeddings\n","emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","print(\"Hugging Face embeddings ready (dim=384)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7De5j-MNWIo","executionInfo":{"status":"ok","timestamp":1754816415006,"user_tz":-330,"elapsed":1428,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"69881a5f-f1ef-4406-a823-a21b0b700fd3"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Hugging Face embeddings ready (dim=384)\n"]}]},{"cell_type":"code","source":["# Extract plain text content and metadata from each chunk for embedding\n","texts = [c.page_content for c in chunks]\n","metadatas = [c.metadata for c in chunks]\n","print(f\"Prepared {len(texts)} chunks for embedding\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzIUVB7JNcRQ","executionInfo":{"status":"ok","timestamp":1754816438559,"user_tz":-330,"elapsed":7,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"3fdc3afb-d497-4efa-9b1e-c918bbdc0cf4"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Prepared 110 chunks for embedding\n"]}]},{"cell_type":"code","source":["# Generate local embeddings for each chunk and confirm vector dimensions\n","vectors = emb.embed_documents(texts)\n","dim = len(vectors[0]) if vectors else 0\n","print(f\"Created {len(vectors)} embeddings, dim={dim}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcThSuZeNf9D","executionInfo":{"status":"ok","timestamp":1754816453447,"user_tz":-330,"elapsed":1032,"user":{"displayName":"Raam Prekash","userId":"03210573549722720918"}},"outputId":"d16bd6d5-eac0-4b81-9f6c-9a3508137e51"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Created 110 embeddings, dim=384\n"]}]}]}